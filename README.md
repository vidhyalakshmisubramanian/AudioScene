# AudioScene
AudioScene â€“ Image to Audio Description System Built an assistive AI system that generates accurate image captions using pretrained visionâ€“language models and converts them into natural speech for accessibility applications. It is designed to help visually impaired users understand visual scenes using image captioning and text-to-speech technology.

## ğŸ”¹ Features
- User image upload
- High-quality image captions using pretrained BLIP
- Natural audio narration (Text-to-Speech)
- Runs entirely in Google Colab

## ğŸ”¹ Technologies Used
- Python
- PyTorch
- Transformers (BLIP)
- gTTS (Text-to-Speech)
- Google Colab

## ğŸ”¹ How It Works
1. User uploads an image
2. The system generates a descriptive caption
3. The caption is converted into speech
4. Audio output is played to the user

## ğŸ”¹ How to Run (Colab)
1. Open the notebook in Google Colab
2. Install dependencies
3. Upload an image
4. Listen to the generated audio description

## ğŸ”¹ Use Cases
- Assistive technology for visually impaired users
- Accessibility-focused AI applications
- Computer vision + audio projects

## ğŸ”¹ Future Enhancements
- Distance and obstacle detection
- Real-time camera input
- Multi-language audio support

## ğŸ‘©â€ğŸ’» Author
Vidhyalakshmi Subramanian
